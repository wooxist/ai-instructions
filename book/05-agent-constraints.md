# 5장. 에이전트 설계: 한계를 넘어 워크플로우를 자동화하는 시스템 구축

**Part 2: 복잡한 인스트럭션 설계**

**목적:** 단일 프롬프트의 한계를 이해하고, 이를 극복하기 위해 역할과 제약이 명확한 '에이전트'를 설계하여 안정적이고 효율적인 자동화 시스템을 구축하는 방법을 배웁니다.

### 이 장에서 배우는 것
- 단일 프롬프트가 가진 본질적 한계(컨텍스트 창, 할루시네이션 등)와 체계적 자동화의 기회.
- 문제 해결 단위로서 '에이전트'의 개념과 시스템적 접근법.
- AI의 한계를 극복하고 업무 효율을 높이기 위한 에이전트 설계 방법론(역할, 제약, 페르소나 등).
- 4장에서 배운 메타 원칙(SoC, 산출물 중심 등)이 에이전트 설계에 어떻게 적용되는지.

## 5.1 왜 '에이전트'를 설계해야 하는가?

지금까지 우리는 좋은 인스트럭션을 만드는 법을 배웠습니다. 하지만 작업이 복잡해지면, 아무리 잘 만든 인스트럭션이라도 하나의 거대한 프롬프트만으로는 한계에 부딪힙니다. '에이전트 설계'는 이러한 한계를 인식하고, 더 나아가 복잡한 업무를 체계적으로 자동화하기 위한 새로운 접근법입니다. 여기에는 두 가지 핵심 동기가 있습니다.

### 5.1.1 [필요의 측면] AI의 본질적 한계 극복

AI 모델은 근본적인 기술적 한계를 가지고 있으며, 이는 단일 프롬프트의 규모가 커질수록 심각한 문제로 나타납니다.

- **한계 1: 컨텍스트 창과 망각:** AI가 한 번에 처리할 수 있는 정보량인 컨텍스트 창(Context Window)[^1]은 제한적입니다. 지시가 길어지면 AI는 앞부분의 중요한 규칙을 잊어버리거나(Lost in the Middle)[^2], 전체적인 일관성을 잃어버립니다.
- **한계 2: 할루시네이션(Hallucination)[^3]:** AI는 사실이 아닌 정보를 그럴듯하게 지어내는 경향이 있습니다. 프롬프트가 복잡하고 여러 소스의 정보를 다룰수록, 할루시네이션이 발생할 가능성은 커지고 결과물의 신뢰도는 떨어집니다.
- **한계 3: 비일관성과 변동성:** 동일한 프롬프트에 대해서도 AI는 미세하게 다른 결과물을 생성합니다. 이는 일관된 결과가 필수적인 업무 자동화에 큰 장애물이 됩니다.
- **한계 4: 유지보수 및 확장성:** 수백, 수천 줄의 거대 프롬프트는 '스파게티 코드'와 같습니다. 작은 수정이 어디에 영향을 미칠지 예측하기 어렵고, 일부 로직만 떼어내 재사용하거나 다른 사람과 협업하기도 거의 불가능합니다.
- **한계 5: 보안 취약점:** 외부 데이터나 사용자 입력에 숨겨진 악의적인 지시(프롬프트 인젝션)[^5]에 취약하여, 의도치 않은 행동을 하거나 민감 정보를 유출할 수 있습니다.

### 5.1.2 [기회의 측면] 체계적인 업무 자동화

반대로, AI의 한계를 인정하고 새로운 접근법을 고민하는 것은 복잡한 업무를 자동화할 엄청난 기회를 열어줍니다.

- **기회 1: 업무의 모듈화 및 재사용:** 복잡한 업무를 '이메일 분류', '데이터 추출', '보고서 초안 작성' 등 잘게 쪼개고, 각 단계를 전담하는 에이전트를 만들면 재사용성이 극대화됩니다. '데이터 추출 에이전트'는 고객 분석뿐만 아니라 재무 분석 워크플로우에도 레고 블록처럼 가져다 쓸 수 있습니다.
- **기회 2: 프로세스 효율성과 확장성:** 표준화된 에이전트들을 조립하여 '월간 보고서 발행'과 같은 복잡한 워크플로우를 빠르고 일관되게 실행할 수 있습니다. 이는 개인의 생산성을 넘어, 팀 전체, 조직 전체로 확장 가능한 자동화 시스템의 기반이 됩니다.
- **기회 3: 명확한 책임과 협업:** 각 에이전트가 맡은 역할과 책임이 명확해져, 문제 발생 시 원인 파악이 쉽습니다. 이는 여러 에이전트 간의 협업은 물론, 사람과 AI의 협업 구조를 명확하게 만드는 효과도 있습니다.

## 5.2 해결 원칙: 단일 책임을 갖는 '에이전트'로 분할하라

앞서 제기된 한계와 기회에 대한 가장 효과적인 해결책은 4장에서 배운 **관심사 분리(SoC, Separation of Concerns)** 원칙을 인스트럭션에 적용하는 것입니다. 즉, 모든 것을 처리하려는 하나의 만능 프롬프트를 버리고, **명확하게 정의된 단일 책임(Single Responsibility)을 가진 전문가 '에이전트'들의 시스템**으로 문제를 해결하는 것입니다.

'에이전트'는 단순히 프롬프트를 나누는 것을 넘어, 특정 역할, 책임, 제약 조건을 가진 독립적인 실행 단위입니다. 예를 들어, '고객 리뷰 분석'이라는 큰 작업은 다음과 같은 에이전트들의 협력으로 수행될 수 있습니다.

1.  **분류 에이전트:** 고객 리뷰를 '긍정', '부정', '문의'로 분류한다.
2.  **핵심 추출 에이전트:** 각 리뷰에서 핵심 불만/칭찬 사항을 추출한다.
3.  **초안 작성 에이전트:** 추출된 내용을 바탕으로 주간 보고서 초안을 작성한다.
4.  **검증 에이전트:** 초안에 할루시네이션이나 왜곡은 없는지 원본 리뷰와 비교하여 검증한다.

이처럼 에이전트 단위로 작업을 분할하면, 각 단계가 단순해져 AI의 한계를 회피하고, 각 에이전트를 독립적으로 개선하거나 재사용하여 업무 효율을 극대화할 수 있습니다.

## 5.3 한계 극복과 효율 증대를 위한 설계 방법론

그렇다면 좋은 에이전트는 어떻게 설계할까요? 에이전트 설계의 각 요소는 5.1절에서 제기된 문제점들을 해결하고 기회를 실현하기 위한 구체적인 방법론과 직접 연결됩니다.

### 5.3.1 [할루시네이션 문제 해결] → 근거 기반 '책임'과 '검증 에이전트' 설계

할루시네이션을 줄이고 신뢰도를 높이기 위해, 에이전트에게 '책임'을 부여하고 '역할'을 분리해야 합니다. 이는 4장의 **투명성 및 추적 가능성(Transparency & Traceability)** 원칙과 연결됩니다.

- **근거 기반 책임 부여:** 모든 '생성' 관련 에이전트에게 "제공된 문서나 데이터 내에서만 정보를 찾아야 하며, 모든 주장은 반드시 출처를 명시해야 한다"는 핵심 **책임**을 부여하고, "추측은 엄격히 금지된다"는 **제약**을 설정합니다.
- **검증 역할 분리:** 더 나아가, 콘텐츠를 생성하는 '생성 에이전트'와 별도로, 생성된 내용의 사실 여부를 확인하는 '검증 에이전트' **역할**을 워크플로우에 포함시킵니다. 이는 사람의 검토 부담을 크게 줄여주면서도 신뢰도를 높이는 효과적인 방법입니다.

### 5.3.2 [컨텍스트 창 문제 해결] → '역할 분할'과 '명시적 제약' 설계

긴 지시를 잊어버리는 문제를 해결하기 위해, 복잡한 작업을 여러 에이전트의 **역할**로 나누어 컨텍스트 창의 부담을 근본적으로 줄여야 합니다. 이는 **관심사 분리(SoC)** 원칙의 가장 중요한 적용 사례입니다. 또한, RAG(Retrieval-Augmented Generation)[^4] 기술을 활용해 필요한 정보만 동적으로 주입하는 것도 효과적입니다.

- **단일 책임 역할 분할:** 하나의 에이전트가 하나의 단순한 작업만 처리하도록 역할을 잘게 나눕니다. 이렇게 하면 각 에이전트의 인스트럭션이 짧고 명확해져, AI가 지시를 잊어버릴 가능성이 현저히 줄어듭니다.
- **망각 방지를 위한 제약 설정:** 그럼에도 불구하고 중요한 규칙이 있다면, "인스트럭션의 가장 중요한 규칙은 맨 마지막에 요약되어 있으니 반드시 다시 참조하라"와 같은 **제약**을 추가하여 망각을 방지할 수 있습니다.

### 5.3.3 [비일관성 문제 해결] → 명확한 '페르소나'와 '구조화된 출력' 설계

결과물의 변동성을 제어하고 일관성을 확보하기 위해, 에이전트의 **페르소나**를 정의하고 **산출물 중심(Output-Driven)** 원칙에 따라 출력 형식을 강제해야 합니다.

- **구체적인 페르소나 부여:** "당신은 20년차 변호사이며, 법률 용어를 정확히 사용하되 고객에게는 쉬운 용어로 설명해야 한다"와 같이 구체적인 **페르소나**를 부여하면, AI의 말투, 관점, 용어 선택이 일관되게 유지됩니다.
- **구조화된 출력 형식 강제:** 자유로운 서술 형식 대신, JSON 스키마, YAML, 표 등 명확한 구조를 가진 출력 형식을 **제약**으로 설정하면, AI가 생성하는 결과의 변동성이 크게 줄어듭니다. 이는 6장에서 더 상세히 다룹니다.

### 5.3.4 [유지보수/확장성 문제 해결] → '모듈화'된 에이전트 설계

'스파게티 프롬프트' 문제를 해결하고 재사용성을 높이기 위해, 각 에이전트를 독립적인 **모듈**로 설계해야 합니다. 이는 **관심사 분리(SoC)**와 **MECE** 원칙을 동시에 적용하는 것입니다.

- **독립적인 모듈 설계:** 각 에이전트를 언제든 교체하거나 개선할 수 있는 독립적인 부품처럼 설계합니다. 예를 들어, '보고서 초안 작성 에이전트'의 성능이 만족스럽지 않다면, 다른 부분에 영향을 주지 않고 해당 에이전트만 교체하거나 업데이트할 수 있습니다.
- **MECE 기반 역할 분배:** 여러 에이전트의 역할을 나눌 때, 서로 중복되지 않고(Mutually Exclusive) 전체 워크플로우를 빠짐없이(Collectively Exhaustive) 처리하도록 **MECE** 원칙에 따라 역할을 분배하면, 시스템 전체의 복잡도가 관리되고 예측 가능성이 높아집니다. 이렇게 설계된 에이전트들은 다른 워크플로우에서 레고 블록처럼 쉽게 재사용될 수 있어, 전체 시스템의 확장성과 생산성을 극대화합니다.

## 실무 예제로 이어보기

이 장에서 배운 개념들을 종합하여 실제 파일 기반 인스트럭션 시스템으로 구축하는 전체 과정은 [8장. 실무 활용하기](08-practical.md)에서 자세히 다룹니다.

## 참고 자료

- Lewis, P., et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. *arXiv preprint arXiv:2005.11401*.
- Liu, N. F., et al. (2023). Lost in the Middle: How Language Models Use Long Contexts. *arXiv preprint arXiv:2307.03172*.

---

[^1]: **컨텍스트 창(Context Window):** AI 모델이 한 번의 상호작용에서 처리하고 기억할 수 있는 최대 정보의 양. 토큰(Token) 단위로 측정되며, 이 크기를 넘어서는 정보는 모델이 인지하지 못할 수 있다.

[^2]: **Lost in the Middle:** 긴 컨텍스트(문맥)를 처리할 때, AI 모델이 입력의 시작이나 끝 부분이 아닌 중간에 위치한 정보를 잘 활용하지 못하거나 잊어버리는 경향을 설명하는 연구 결과.

[^3]: **할루시네이션(Hallucination):** AI 모델이 학습 데이터에 근거하지 않거나 사실과 다른 내용을, 마치 실제 사실인 것처럼 그럴듯하게 생성하는 현상. '의도치 않은 정보 날조' 또는 '그럴듯한 거짓말'이라고도 불린다.

[^4]: **RAG(Retrieval-Augmented Generation):** 대규모 언어 모델(LLM)이 답변을 생성할 때, 미리 준비된 외부 지식 베이스에서 관련된 정보를 실시간으로 검색(Retrieval)하고, 이 정보를 참고하여 답변 생성을 보강(Augmented Generation)하는 기술. 할루시네이션을 줄이고 정보의 최신성을 확보하는 데 효과적이다.

[^5]: **프롬프트 인젝션(Prompt Injection):** 사용자의 입력값에 악의적인 지시를 몰래 삽입하여, AI가 원래의 지시를 무시하고 공격자의 의도대로 작동하도록 만드는 보안 공격 기법.