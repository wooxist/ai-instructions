# 10장 4부: 고급 아키텍처와 실전 구현

---

## 10.10 [보충 예제] 계층적 에이전트 협력 시스템

- **상황:** 신제품 출시를 위한 종합 마케팅 캠페인을 기획하고 실행하는 프로젝트. 메타-보스-비서-매니저-워커의 5계층 구조를 활용합니다.

#### 워크플로우 구조

```markdown
# 계층적 협력 시스템: 신제품 마케팅 캠페인

## [계층 1] 메타 에이전트
- **역할:** 캠페인 아키텍트
- **책임:**
  - 신제품의 특성과 목표 시장을 분석하여 필요한 에이전트 팀 구성 설계
  - 보스 에이전트에게 전체 전략 방향 제시
  - 시스템 전체의 워크플로우 설계

## [계층 2] 보스 에이전트
- **역할:** 마케팅 디렉터
- **책임:**
  - "출시 3개월 내 10,000명의 얼리어답터 확보"라는 최종 목표 설정
  - 전략을 3개 매니저(콘텐츠, 퍼포먼스, PR)에게 위임
  - 비서로부터 받은 진행 상황 보고 기반 의사결정

## [계층 3] 비서 에이전트
- **역할:** 전략 보좌관
- **책임:**
  - 경쟁사 분석, 시장 트렌드 등 정보 수집 및 요약
  - 각 매니저의 주간 진행 상황을 수집하여 보스에게 대시보드 형식으로 보고
  - 보스의 의사결정에 필요한 데이터 분석 지원

## [계층 4] 매니저 에이전트들
### 매니저 A: 콘텐츠 매니저
- 블로그, 영상, SNS 콘텐츠 전략 수립
- 콘텐츠 제작 워커들 조율

### 매니저 B: 퍼포먼스 마케팅 매니저
- 광고 예산 배분 및 채널 선정
- 광고 집행 워커들 관리

### 매니저 C: PR 매니저
- 언론사 관계 관리 및 보도자료 전략
- PR 활동 워커들 지휘

## [계층 5] 워커 에이전트들
- 블로그 글 작성 워커
- 영상 스크립트 작성 워커
- 광고 카피 생성 워커
- 보도자료 작성 워커
- 데이터 분석 워커
```

#### 설계 분석
- **메타 원칙 (4장):** **SoC** 원칙에 따라 각 계층이 자신의 추상화 수준에서 역할을 수행합니다. 메타는 '설계', 보스는 '전략', 비서는 '정보', 매니저는 '전술', 워커는 '실행'을 담당합니다.
- **에이전트 설계 (5장):** 각 계층은 명확한 **권한과 책임의 범위**를 가지며, 상위 계층은 하위 계층에 직접 지시하지 않고 바로 아래 계층을 통해 간접적으로 조율합니다.
- **워크플로우 설계 (7장):** **계층적 협력 시스템**의 전형적인 예로, 복잡한 목표를 체계적으로 분해하고 각 계층이 최적의 의사결정을 내립니다.

---

## 10.11 [보충 예제] 수평적 에이전트 협력 시스템

- **상황:** 스타트업 투자 검토를 위한 실사(Due Diligence). 법률, 재무, 기술, 시장 4개 영역의 전문가 에이전트가 동등한 위치에서 협력합니다.

#### 워크플로우 구조

```markdown
# 수평적 협력 시스템: 투자 실사 전문가 패널

## 전문가 패널 구성

### 전문가 1: 법률 검토 에이전트
- **역할:** 법무법인 변호사
- **담당:** 회사 정관, 계약서, IP 권리, 소송 이력 검토
- **출력:** 법률 리스크 평가 보고서 (JSON)

### 전문가 2: 재무 검토 에이전트
- **역할:** 회계법인 공인회계사
- **담당:** 재무제표 분석, 현금흐름, 부채 구조 검토
- **출력:** 재무 건전성 평가 보고서 (JSON)

### 전문가 3: 기술 검토 에이전트
- **역할:** 시니어 CTO
- **담당:** 코드 품질, 아키텍처, 기술 부채, 보안 취약점 분석
- **출력:** 기술 역량 평가 보고서 (JSON)

### 전문가 4: 시장 검토 에이전트
- **역할:** 산업 애널리스트
- **담당:** 시장 규모, 경쟁 구도, 성장 가능성 분석
- **출력:** 시장 기회 평가 보고서 (JSON)

## 협력 프로세스

1. **병렬 분석 단계**
   - 4명의 전문가가 동시에 각자의 영역을 독립적으로 분석
   - 각자 정해진 평가 기준에 따라 1-10점 척도로 점수 부여

2. **교차 검토 단계** (수평적 피드백)
   - 법률 전문가 ↔ 재무 전문가: 계약서의 재무 조건 교차 검증
   - 기술 전문가 ↔ 시장 전문가: 기술의 시장 경쟁력 교차 검증
   - 각 쌍이 서로의 보고서를 검토하고 이슈 제기

3. **합의 도출 단계**
   - 종합 회의 에이전트가 4개 보고서를 통합
   - 의견 불일치 항목에 대해 투표 또는 가중 평균으로 최종 결론
   - 최종 투자 권고안 (투자/보류/거부) 생성

## 출력 형식
{
  "decision": "투자|보류|거부",
  "overall_score": 7.5,
  "expert_scores": {
    "legal": 8,
    "financial": 7,
    "technical": 9,
    "market": 6
  },
  "red_flags": ["항목1", "항목2"],
  "recommendations": ["조건1", "조건2"]
}
```

#### 설계 분석
- **메타 원칙 (4장):** **MECE** 원칙에 따라 4개 영역이 상호 배타적이며 전체를 빠짐없이 커버합니다. **피드백 루프**를 통해 전문가 간 교차 검증으로 정확도를 높입니다.
- **에이전트 설계 (5장):** 각 전문가 에이전트는 동등한 **권한**을 가지며, 누구도 다른 전문가에게 명령할 수 없습니다. 오직 각자의 전문 영역에서만 최종 판단을 내립니다.
- **워크플로우 설계 (7장):** **수평적 협력 시스템**의 '전문가 패널' 패턴과 '동료 검토' 패턴을 결합하여, 의사결정의 분산과 전문성 보장을 동시에 달성합니다.

---

## 10.12 [미래 예제] 시스템을 '개선'하는 메타 에이전트

- **상황:** 8.9의 '주간 고객 리뷰 분석 시스템'이 잘 운영되고 있지만, "API 비용이 너무 많이 나온다"는 새로운 비즈니스 요구사항이 발생했다.
- **에이전트 역할:** AI 시스템 최적화 아키텍트 (메타 에이전트)

#### 최종 인스트럭션 예시
```markdown
# 역할: AI 시스템 최적화 아키텍트 (메타 에이전트)

# 목표
현재 운영 중인 '주간 고객 리뷰 분석 시스템'의 API 비용을 20% 절감하라. 단, 최종 보고서의 품질(정확도)은 5% 이상 하락해서는 안 된다.

# 입력 데이터
1. 현재 시스템의 모든 인스트럭션 파일 (`/instructions/weekly_review_report/`)
2. 지난 1달간의 성능 로그 데이터 (`perf_log.csv`)

# 기초 지식 및 원칙
- **성능의 삼각형 (10장):** 모든 결정은 품질, 비용, 속도 간의 트레이드오프를 고려해야 한다.
- **관심사 분리 (SoC, 4장):** 에이전트의 역할을 분리하거나 통합하는 제안을 할 때, 각 에이전트가 단일 책임을 갖도록 유도해야 한다.
- **산출물 중심 (4장):** 변경을 제안할 때는, 변경된 산출물의 형식과 구조를 명확히 정의해야 한다.
- **점진적 개선 (4장):** 한 번에 많은 것을 바꾸기보다, 측정 가능한 작은 단위를 변경하고 테스트하는 계획을 선호한다.
- **데이터 기반 평가 (11장):** 모든 개선 제안은 반드시 A/B 테스트와 같은 정량적 평가 계획을 동반해야 한다.

# 처리 방법
1. `[#기초 지식 및 원칙]`을 바탕으로, `[#입력 데이터]`를 분석하여 `[#목표]`를 달성하기 위한 계획을 수립한다.
2. 비용이 가장 많이 발생하는 에이전트나 단계를 식별한다.
3. 비용 절감을 위한 개선 가설을 2가지 이상 수립한다.
   - 가설 예시 1: "Summarizer 에이전트의 모델을 GPT-4에서 Claude 3 Sonnet으로 변경한다."
   - 가설 예시 2: "Classifier 에이전트의 인스트럭션에서 불필요한 예시를 제거하여 프롬프트 토큰을 줄인다."
4. 각 가설에 따라, 관련된 인스트럭션 파일의 수정안(`v2`)을 생성한다.
5. 생성된 수정안을 검증하기 위한 A/B 테스트 실행 계획서를 작성한다.

# 출력물
- 수정된 인스트럭션 파일(들)의 내용.
- A/B 테스트 실행 계획서.
```

#### 설계 분석
- **메타 원칙 (4장):** 이 에이전트는 스스로 **점진적 개선, 피드백 루프, 데이터 기반 의사결정** 등 다양한 메타 원칙을 활용하여 기존 시스템을 분석하고 개선하는 작업을 수행합니다.
- **에이전트 설계 (5장):** '시스템 최적화 아키텍트'라는 고도의 **역할**을 부여받아, 다른 에이전트들의 설계를 변경하는 메타 작업을 수행합니다.
- **입/출력 설계 (6장):** 이 에이전트의 **입력**은 다른 에이전트의 인스트럭션 파일과 성능 로그 데이터이며, **출력**은 수정된 인스트럭션 파일과 테스트 계획서입니다. 즉, 코드(인스트럭션)를 입력받아 코드를 출력하는 '코드 생성 코드'와 같은 구조입니다.
- **워크플로우 설계 (7장):** '분석 → 가설 수립 → 수정안 생성 → 검증 계획 수립'이라는 고수준의 **워크플로우**를 내부적으로 따릅니다.

---

## 10.13 [실전 코딩] 9장의 '평가 에이전트' 직접 만들어보기

9장에서 우리는 인스트럭션을 객관적으로 평가하는 방법과 '평가 에이전트'의 개념에 대해 배웠습니다. 이 섹션에서는 그 개념을 실제 파이썬 코드로 구현하는 구체적인 예제를 다룹니다. 이 예제를 통해 여러분은 더 이상 '감'이 아닌 데이터로 프롬프트의 성능을 측정하는 방법을 직접 경험하게 될 것입니다.

### 시나리오

비정형 텍스트에서 사용자의 이름과 이메일을 JSON 형식으로 추출하는 작업을 가정해 봅시다. 우리는 두 가지 버전의 프롬프트를 테스트하여 어느 것이 더 안정적으로 정확한 JSON을 생성하는지 평가하고자 합니다.

### 사전 준비물

- **Python 3.7 이상**이 설치된 환경
- **OpenAI API 키:** OpenAI 플랫폼에서 발급받은 API 키가 필요합니다. 스크립트를 실행하기 전에 환경 변수로 키를 설정해야 합니다.
  ```bash
  export OPENAI_API_KEY='sk-...' # 실제 키로 대체
  ```
- **OpenAI 라이브러리 설치:** 
  ```bash
  pip install openai
  ```

### 1단계: 평가 데이터셋과 프롬프트 준비

먼저 테스트에 사용할 '골든 데이터셋'과 성능을 비교할 두 프롬프트를 정의합니다.

- **골든 데이터셋:** 테스트할 입력(input)과, 해당 입력에 대한 완벽한 정답(ground_truth)의 쌍으로 구성됩니다.
- **프롬프트 A:** 간단하고 직접적인 요청.
- **프롬프트 B:** Few-shot 예시와 더 명확한 출력 형식을 포함한 개선된 요청.

### 2단계: '평가 에이전트' 코드 작성 (Python)

이제 전체 프로세스를 자동화하는 파이썬 스크립트를 작성합니다. 이 스크립트가 바로 우리의 '평가 에이전트'입니다.

```python
import os
import json
from openai import OpenAI

# 1. 사전 준비
# ----------------------------------------------------------------------------
# OpenAI 클라이언트 초기화
# 코드가 환경 변수에서 API 키를 자동으로 읽어들입니다.
client = OpenAI()

# 골든 데이터셋 정의
golden_dataset = [
    {
        "id": "case1",
        "input": "제 이름은 김민준이고, 이메일은 mj.kim@example.com 입니다. 연락주세요.",
        "ground_truth": {"name": "김민준", "email": "mj.kim@example.com"}
    },
    {
        "id": "case2",
        "input": "연락처: 이서연 (sy.lee@example.com)",
        "ground_truth": {"name": "이서연", "email": "sy.lee@example.com"}
    },
    {
        "id": "case3",
        "input": "박지훈입니다. 이메일 주소는 없지만, 제 웹사이트는 phoon.co 입니다.",
        "ground_truth": {"name": "박지훈", "email": None}
    }
]

# 프롬프트 버전 정의
prompt_a = """
다음 텍스트에서 이름과 이메일 주소를 추출하여 JSON 형식으로 반환하세요.
TEXT: {text}
"""

prompt_b = """
당신은 텍스트에서 개인 정보를 추출하는 전문 AI입니다.
주어진 텍스트에서 이름(name)과 이메일(email)을 추출하여 JSON 형식으로 반환하세요.

# 예시
- Text: "담당자는 최수빈이고, 이메일은 sb.choi@example.com 입니다."
- Output: {{"name": "최수빈", "email": "sb.choi@example.com"}}

# 규칙
- 만약 이메일 주소가 없다면, email 필드의 값은 null로 설정하세요.
- 다른 말은 절대 하지 말고, JSON 객체만 반환해야 합니다.

TEXT: {text}
"""

prompts = {"prompt_a": prompt_a, "prompt_b": prompt_b}

# 2. 핵심 함수 정의
# ----------------------------------------------------------------------------
def get_llm_response(prompt, text):
    """주어진 프롬프트와 텍스트로 LLM API를 호출하는 함수"""
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt.format(text=text)}
            ],
            temperature=0
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error: {e}"

def judge_response(response_text, ground_truth):
    """LLM-as-a-Judge: 결과물을 평가하고 점수를 매기는 함수"""
    score = 0
    # 평가 기준 1: 유효한 JSON인가?
    try:
        response_json = json.loads(response_text)
        score += 50
    except json.JSONDecodeError:
        return 0 # JSON 파싱 실패 시 0점 처리

    # 평가 기준 2: 추출된 데이터가 정답과 일치하는가?
    if response_json.get("name") == ground_truth.get("name") and \
       response_json.get("email") == ground_truth.get("email"):
        score += 50
    
    return score

# 3. 평가 에이전트 실행
# ----------------------------------------------------------------------------
results = {}

for prompt_name, prompt_template in prompts.items():
    print(f"--- {prompt_name.upper()} 평가 시작 ---")
    total_score = 0
    prompt_results = []

    for item in golden_dataset:
        case_id = item["id"]
        input_text = item["input"]
        truth = item["ground_truth"]

        # 1. LLM으로부터 답변 생성
        response = get_llm_response(prompt_template, input_text)

        # 2. 심판(Judge)을 통해 결과 채점
        score = judge_response(response, truth)
        total_score += score

        prompt_results.append({
            "case_id": case_id,
            "response": response,
            "score": score
        })
        print(f"  Case {case_id}: Score {score}/100")

    results[prompt_name] = {
        "details": prompt_results,
        "average_score": total_score / len(golden_dataset)
    }
    print(f"--- {prompt_name.upper()} 평가 종료 ---
")

# 4. 최종 리포트 생성
# ----------------------------------------------------------------------------
print("========== 최종 평가 리포트 ==========")
for prompt_name, result_data in results.items():
    print(f"프롬프트: {prompt_name}")
    print(f"  평균 점수: {result_data['average_score']:.2f}")
print("======================================")

# 상세 결과 출력 (옵션)
# import pprint
# pprint.pprint(results)

```

### 3단계: 실행 및 결과 리포트 확인

위 스크립트를 `evaluation_agent.py`로 저장하고 터미널에서 실행합니다.

```bash
python evaluation_agent.py
```

스크립트가 실행되면, 각 프롬프트와 각 테스트 케이스에 대한 채점 과정을 볼 수 있습니다. 모든 평가가 끝나면 다음과 같은 최종 리포트를 얻게 됩니다.

```
--- PROMPT_A 평가 시작 ---
  Case case1: Score 100/100
  Case case2: Score 0/100
  Case case3: Score 0/100
--- PROMPT_A 평가 종료 ---

--- PROMPT_B 평가 시작 ---
  Case case1: Score 100/100
  Case case2: Score 100/100
  Case case3: Score 100/100
--- PROMPT_B 평가 종료 ---

========== 최종 평가 리포트 ==========
프롬프트: prompt_a
  평균 점수: 33.33
프롬프트: prompt_b
  평균 점수: 100.00
======================================
```

이 리포트를 통해 우리는 **프롬프트 B가 프롬프트 A보다 훨씬 더 안정적으로 원하는 결과물을 생성한다**는 사실을 '감'이 아닌 '데이터'로 명확히 증명할 수 있습니다. 프롬프트 A는 간단한 케이스는 잘 처리했지만, 형식이 조금만 달라지거나 예외적인 상황(이메일 없음)에서는 실패했기 때문입니다.

### 결론

이 예제는 '평가 에이전트'의 가장 기본적인 형태입니다. 여기서 더 나아가 심판(Judge)의 평가 기준을 더 정교하게 만들거나, 'LLM-as-a-Judge'를 활용하여 점수뿐만 아니라 '실패 원인'까지 분석하게 만들 수도 있습니다. 

중요한 것은 이러한 자동화된 평가 시스템을 통해, 우리는 인스트럭션 개선 작업을 훨씬 더 빠르고, 정확하고, 자신감 있게 수행할 수 있다는 점입니다. 여러분도 자신의 중요한 반복 작업에 이 '평가 에이전트' 패턴을 적용하여 프롬프트를 과학적으로 관리해 보세요.


## 마치며: 패턴에서 원칙으로

이 장에서는 4장부터 9장까지 배운 설계 원칙과 방법론이 실제 상황에서 어떻게 적용되는지 9가지 매트릭스 상황과 추가 보충 예제를 통해 살펴보았습니다.

중요한 것은 이 예제들을 '정답'으로 외우는 것이 아니라, **왜 그렇게 설계되었는지**를 이해하는 것입니다. 각 예제의 설계 분석에서 반복적으로 언급된 메타 원칙들—**SoC, MECE, SSOT, 산출물 중심, 피드백 루프, Human-in-the-Loop**—이 바로 좋은 인스트럭션 시스템의 핵심 DNA입니다.

여러분이 마주한 새로운 문제는 이 예제들과 정확히 같지 않을 것입니다. 하지만 이 장에서 본 패턴들을 참고하고, 그 뒤에 숨은 원칙을 적용한다면, 어떤 상황에서도 효과적인 인스트럭션 시스템을 설계할 수 있을 것입니다.

다음 장부터는 인스트럭션 시스템을 실제로 구축하고 관리하는 데 필요한 도구와 프레임워크, 그리고 시스템을 지속적으로 발전시키는 전략을 다룹니다.

## 참고 자료

본 장의 예제들은 다음 자료와 개념을 참고하여 작성되었습니다:

- **RAG (Retrieval-Augmented Generation):** Lewis, P., et al. (2020). "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks." *Proceedings of NeurIPS 2020*.
- **AI 에이전트 아키텍처:** Anthropic. (2024). "Building effective agents." *Anthropic Documentation*. https://docs.anthropic.com/en/docs/build-with-claude/develop/agentic-systems
- **Multi-Agent Systems:** Wooldridge, M. (2009). *An Introduction to MultiAgent Systems* (2nd ed.). Wiley.
- **실무 사례 연구:** OpenAI. (2024). "GPT Best Practices." *OpenAI Documentation*.
```