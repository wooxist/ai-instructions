# 4장. 기본 정보 채워넣기

**1부: 인스트럭션의 기초와 설계 원칙**

**목적:** AI가 혼동하지 않도록 필수 정보를 ‘무엇을·얼마나·어떤 형식으로’ 채워 넣는 법을 익힌다.

### 이 장에서 배우는 것
- 컨텍스트를 앞·중·뒤 어디에 얼마나 제공할지
- 출력 형식(JSON/표/마크다운)과 검증 규칙 정하기
- Few/Zero-shot 예시로 기대 형식·톤을 정렬하기

### 스코프 안내
이 장은 지시에 ‘채워 넣는 요소(컨텍스트/형식/예시)’를 다룹니다. 지시의 구조와 성공 기준은 3장에서, 제한/대응 전략은 7장에서 다룹니다.

## 4.1 컨텍스트(Context) 제공하기
컨텍스트는 작업의 배경·제약·전제를 짧고 명확하게 전달하는 것입니다.

### 언제 유용한가
새로운 도메인/프로젝트, 정책·보안 제약이 있는 작업, 특정 조건을 전제로 하는 분석/생성 과업

### 언제 안 쓰나
즉시 결정만 필요한 단답형 판단(폐쇄형/비교형으로 충분) 또는 이미 모든 전제가 지시에 포함된 경우

### 예시
"배경: B2B SaaS 리텐션 분석 | 대상: 지난달 유료 플랜 사용자 | 제외: 프로모션 사용자 | 지표: D30 리텐션 | 특이: 주말 트래픽 왜곡"

### 나쁜예
"상황은 알아서 판단해서 분석해줘"

### 이렇게 적어보세요
"배경: … | 목표: … | 대상/기간: … | 데이터/출처: … | 제약/정책: … | 가정: …"

### 자주하는 실수
불필요한 배경 과다(핵심이 묻힘), 오래된 정보/링크, 전제/제약 누락, 지시와 컨텍스트를 뒤섞음

### 더 좋게
핵심은 맨 앞(TL;DR), 불릿으로 요약, 중요도 순 정렬(필수→선택), 필요한 곳에서만 세부 링크 제공

### 성공 기준 예시
핵심 전제·제약이 맨 앞에 요약되고(3줄), 지시와 충돌/모순이 없으며, 모델이 그 전제를 실제로 반영해 출력

참고: 지시 구조/성공 기준은 3장, 제한/대응 전략은 7장 참조

## 4.2 출력 형식 지정
형식 지정은 사람이든 기계든 검증·재사용이 쉽게 만드는 핵심입니다.

### 언제 유용한가
머신 판독(JSON/CSV), 팀 리뷰(표/마크다운), 자동화 파이프라인 입력 등 형식 준수가 중요한 경우

### 언제 안 쓰나
초기 탐색 대화처럼 형식보다 아이디어 발산이 목적일 때(단, 최종 정리 단계에 형식 지정 권장)

### 예시
JSON 스키마:
```
{
  "type": "object",
  "required": ["summary", "items"],
  "properties": {
    "summary": { "type": "string" },
    "items": {
      "type": "array",
      "items": { "type": "object", "required": ["title", "action"],
        "properties": { "title": {"type": "string"}, "action": {"type": "string"} }
      }
    }
  }
}
```

표(마크다운):
```
| 항목 | 값 | 비고 |
|---|---|---|
| 전환율 | 3.2% | 최근 7일 |
| CPA | 18,000원 | 목표치 충족 |
```

### 나쁜예
"형식은 알아서" / "표로"(컬럼·정렬·단위 미지정) / JSON에 주석·자유 텍스트 섞기

### 이렇게 적어보세요
"형식: JSON(스키마 위와 동일) | 검증: 실패 시 재생성 | 표시는 마크다운 표(컬럼: …) | 길이: 항목 5개 이내"

### 자주하는 실수
필수 필드 누락, 단위/포맷 미명시, JSON에 설명 텍스트 삽입, 표의 열 순서/헤더 누락

### 더 좋게
유효한 예시 1개를 함께 제공, 코드펜스로 감싸 파싱 안정화, 키 이름·단위 표준화(SSOT)

### 성공 기준 예시
스키마/표 형식 검증 통과, 필수 필드·열·단위 100% 충족, 불필요한 텍스트 없음

참고: 지시 구조/성공 기준은 3장, 제한/대응 전략은 7장 참조

## 4.3 Few-shot / Zero-shot 예시 활용
짧은 예시로 기대 형식·톤·깊이를 정렬합니다.

### 언제 유용한가
특정 톤/형식 요구, 도메인 특화 표현, 단계적 추론(Chain-of-Thought) 유도

### 언제 안 쓰나
컨텍스트 창이 빠듯할 때 장문의 예시 다수(필요 시 짧고 핵심만, 1–2개 권장)

### 예시
```
예시 입력: “지표를 요약해줘”
예시 출력: “불릿 3개(전환율/CPA/주요변동), 마지막에 다음 액션 1개”
```

### 나쁜예
장문 예시 5개 이상, 실제 과업과 무관한 형식, 예시와 본문 지시가 충돌

### 이렇게 적어보세요
"예시는 2개 이내, 각 2–3줄. 본 요청은 ‘예시 출력 형식’을 따릅니다. 길이 제한: 불릿 3개+액션 1개"

### 자주하는 실수
예시가 본문보다 길어 핵심 지침이 밀림, 예시/본문 불일치, 한/영 혼용으로 톤 혼란

### 더 좋게
예시 뒤에 ‘실제 요청’을 분리해 배치, 도메인 용어·톤을 예시로 선제 정의

### 성공 기준 예시
출력이 예시 형식·톤을 정확히 따르고, 길이 제한·언어 지시(한국어)를 준수

참고: 지시 구조/성공 기준은 3장, 제한/대응 전략은 7장 참조

---

## 참고 자료

- Brown, T., et al. (2020). Language Models are Few-Shot Learners. arXiv preprint arXiv:2005.14165.
- Liu, J., et al. (2023). Lost in the Middle: How Language Models Use Long Contexts. arXiv preprint arXiv:2307.03172.
- Wei, J., et al. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models. arXiv preprint arXiv:2201.11903.
- White, J., et al. (2023). A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT. arXiv preprint arXiv:2302.11382.
- Microsoft. (2023). Prompt Engineering Guide. https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering

---

**상태:** v1-draft  
**작성 시작일:** 2025-09-27
