# Copy to .env and fill in as needed

# Cloud API keys (optional)
OPENAI_API_KEY=
ANTHROPIC_API_KEY=

# Local LLM (optional)
OLLAMA_HOST=127.0.0.1:11434
OLLAMA_MODEL=llama3.1:8b

# Defaults for lab scripts
MODEL=gpt-4o-mini
ANTHROPIC_MODEL=claude-3-5-sonnet-latest

# Routing controls
# If set to one of: ollama|openai|anthropic|dummy, forces that route (when available)
ROUTE_FORCE=
# Prefer local for inputs up to this length
ROUTE_OLLAMA_MAX_CHARS=280
# Route priority order (first available is selected, ollama also checks length)
ROUTE_ORDER=ollama,openai,anthropic

# Estimated costs (USD per 1K tokens)
# Set per your provider/model pricing. Defaults are 0 (no cost).
OPENAI_INPUT_COST_PER_1K=0
OPENAI_OUTPUT_COST_PER_1K=0
ANTHROPIC_INPUT_COST_PER_1K=0
ANTHROPIC_OUTPUT_COST_PER_1K=0
OLLAMA_COST_PER_1K=0
DUMMY_COST_PER_1K=0

# Token estimation (tokens per char overrides)
# Global default if per-provider not set
TOKENS_PER_CHAR=
OPENAI_TOKENS_PER_CHAR=
ANTHROPIC_TOKENS_PER_CHAR=
OLLAMA_TOKENS_PER_CHAR=
DUMMY_TOKENS_PER_CHAR=

# Reports
REPORT_RECENT_N=20
